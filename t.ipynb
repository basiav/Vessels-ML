{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d9eff76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import yaml\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "\n",
    "class LesionYOLOTrainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_images_dir=\"data/Dataset/base_images\",\n",
    "        lesion_data_path=\"data/Dataset/lesion_data.csv\",\n",
    "    ):\n",
    "        self.base_images_dir = base_images_dir\n",
    "        self.lesion_data_path = lesion_data_path\n",
    "        self.dataset_dir = \"yolo_dataset\"\n",
    "        self.lesion_df = None\n",
    "\n",
    "    def load_data(self):\n",
    "        print(\"Loading lesion data...\")\n",
    "        self.lesion_df = pd.read_csv(self.lesion_data_path)\n",
    "        print(f\"Loaded {len(self.lesion_df)} lesion annotations\")\n",
    "\n",
    "    def create_dataset_structure(self):\n",
    "        print(\"Creating dataset structure...\")\n",
    "\n",
    "        for split in [\"train\", \"val\"]:\n",
    "            os.makedirs(f\"{self.dataset_dir}/{split}/images\", exist_ok=True)\n",
    "            os.makedirs(f\"{self.dataset_dir}/{split}/labels\", exist_ok=True)\n",
    "\n",
    "    def convert_to_yolo_format(self, x, y, width, height, img_width, img_height):\n",
    "        center_x = x + width / 2\n",
    "        center_y = y + height / 2\n",
    "\n",
    "        norm_center_x = center_x / img_width\n",
    "        norm_center_y = center_y / img_height\n",
    "        norm_width = width / img_width\n",
    "        norm_height = height / img_height\n",
    "\n",
    "        return norm_center_x, norm_center_y, norm_width, norm_height\n",
    "\n",
    "    def process_annotations(self):\n",
    "        print(\"Processing annotations...\")\n",
    "\n",
    "        grouped = self.lesion_df.groupby([\"image_id\", \"frame\"])\n",
    "\n",
    "        image_annotations = {}\n",
    "\n",
    "        for (image_id, frame), group in grouped:\n",
    "            image_filename = f\"{image_id}_{frame}.png\"\n",
    "            image_path = os.path.join(self.base_images_dir, image_filename)\n",
    "\n",
    "            if not os.path.exists(image_path):\n",
    "                print(f\"WARNING: Image {image_filename} not found, skipping...\")\n",
    "                continue\n",
    "\n",
    "            img = cv2.imread(image_path)\n",
    "            if img is None:\n",
    "                print(\n",
    "                    f\"WARNING: Image exists, but cannot be loaded {image_filename}, skipping...\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            img_height, img_width = img.shape[:2]\n",
    "\n",
    "            annotations = []\n",
    "            for _, row in group.iterrows():\n",
    "                x = row[\"lesion_x\"]\n",
    "                y = row[\"lesion_y\"]\n",
    "                width = row[\"lesion_width\"]\n",
    "                height = row[\"lesion_height\"]\n",
    "\n",
    "                if (\n",
    "                    pd.isna(row[\"lesion_x\"])\n",
    "                    or pd.isna(row[\"lesion_y\"])\n",
    "                    or pd.isna(row[\"lesion_width\"])\n",
    "                    or pd.isna(row[\"lesion_height\"])\n",
    "                ):\n",
    "                    continue\n",
    "\n",
    "                norm_cx, norm_cy, norm_w, norm_h = self.convert_to_yolo_format(\n",
    "                    x, y, width, height, img_width, img_height\n",
    "                )\n",
    "\n",
    "                if not (\n",
    "                    0 <= norm_cx <= 1\n",
    "                    and 0 <= norm_cy <= 1\n",
    "                    and 0 <= norm_w <= 1\n",
    "                    and 0 <= norm_h <= 1\n",
    "                ):\n",
    "                    print(\n",
    "                        f\"WARNING: Invalid normalized coordinates for {image_filename}: cx={norm_cx}, cy={norm_cy}, w={norm_w}, h={norm_h}\"\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "                annotations.append(\n",
    "                    f\"0 {norm_cx:.6f} {norm_cy:.6f} {norm_w:.6f} {norm_h:.6f}\"\n",
    "                )\n",
    "\n",
    "            image_annotations[image_filename] = annotations\n",
    "\n",
    "        return image_annotations\n",
    "\n",
    "    def split_dataset(self, image_annotations, train_ratio=0.8):\n",
    "        print(\"Splitting dataset...\")\n",
    "\n",
    "        image_files = list(image_annotations.keys())\n",
    "        train_files, val_files = train_test_split(\n",
    "            image_files, train_size=train_ratio, random_state=42\n",
    "        )\n",
    "\n",
    "        print(f\"Training images: {len(train_files)}\")\n",
    "        print(f\"Validation images: {len(val_files)}\")\n",
    "\n",
    "        return train_files, val_files\n",
    "\n",
    "    def copy_files_and_create_labels(self, image_annotations, train_files, val_files):\n",
    "        print(\"Copying files and creating labels...\")\n",
    "\n",
    "        for split, files in [(\"train\", train_files), (\"val\", val_files)]:\n",
    "            for image_file in files:\n",
    "                # Copy image\n",
    "                src_image = os.path.join(self.base_images_dir, image_file)\n",
    "                dst_image = os.path.join(self.dataset_dir, split, \"images\", image_file)\n",
    "                shutil.copy2(src_image, dst_image)\n",
    "\n",
    "                label_file = image_file.replace(\".png\", \".txt\")\n",
    "                label_path = os.path.join(self.dataset_dir, split, \"labels\", label_file)\n",
    "\n",
    "                with open(label_path, \"w\") as f:\n",
    "                    for annotation in image_annotations[image_file]:\n",
    "                        f.write(annotation + \"\\n\")\n",
    "\n",
    "    def create_yaml_config(self):\n",
    "        config = {\n",
    "            \"path\": os.path.abspath(self.dataset_dir),\n",
    "            \"train\": \"train/images\",\n",
    "            \"val\": \"val/images\",\n",
    "            \"nc\": 1,\n",
    "            \"names\": [\"lesion\"],\n",
    "        }\n",
    "\n",
    "        config_path = os.path.join(self.dataset_dir, \"dataset.yaml\")\n",
    "        with open(config_path, \"w\") as f:\n",
    "            yaml.dump(config, f, default_flow_style=False)\n",
    "\n",
    "        print(f\"Created YAML config at {config_path}\")\n",
    "        return config_path\n",
    "\n",
    "    def prepare_dataset(self):\n",
    "        self.load_data()\n",
    "        self.create_dataset_structure()\n",
    "\n",
    "        image_annotations = self.process_annotations()\n",
    "        train_files, val_files = self.split_dataset(image_annotations)\n",
    "        self.copy_files_and_create_labels(image_annotations, train_files, val_files)\n",
    "\n",
    "        config_path = self.create_yaml_config()\n",
    "        return config_path\n",
    "\n",
    "    def train_model(self, config_path, model_size=\"yolov8n\", epochs=100, imgsz=512):\n",
    "        print(f\"Starting YOLO training with {model_size}...\")\n",
    "\n",
    "        model = YOLO(f\"{model_size}.pt\")\n",
    "        results = model.train(\n",
    "            data=config_path,\n",
    "            epochs=epochs,\n",
    "            imgsz=imgsz,\n",
    "            patience=10,\n",
    "            save=True,\n",
    "            # device=\"CUDA\", :-(\n",
    "            device=\"cpu\",\n",
    "            workers=4,\n",
    "            batch=16,\n",
    "            name=\"lesion_detection\",\n",
    "            degrees=15.0,  # rotation augmentation (Â±15 degrees)\n",
    "            flipud=0.5,  # vertical flipping at 50%\n",
    "            fliplr=0.5,  # horizontal flipping at 50%\n",
    "        )\n",
    "\n",
    "        print(\"Training completed!\")\n",
    "        return model, results\n",
    "\n",
    "    def evaluate_model(self, model):\n",
    "        print(\"Evaluating model...\")\n",
    "\n",
    "        metrics = model.val()\n",
    "\n",
    "        print(f\"mAP50: {metrics.box.map50:.4f}\")\n",
    "        print(f\"mAP50-95: {metrics.box.map:.4f}\")\n",
    "        print(f\"Precision: {metrics.box.precision:.4f}\")\n",
    "        print(f\"Recall: {metrics.box.recall:.4f}\")\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def predict_sample(self, model, image_path, conf_threshold=0.25):\n",
    "        print(f\"Making prediction on {image_path}...\")\n",
    "\n",
    "        results = model.predict(\n",
    "            image_path,\n",
    "            conf=conf_threshold,\n",
    "            save=True,\n",
    "            show_labels=True,\n",
    "            show_conf=True,\n",
    "        )\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "def predict_multiple_samples(self, model, num_samples=10, conf_threshold=0.25):\n",
    "    print(f\"Making predictions on {num_samples} sample images...\")\n",
    "\n",
    "    sample_images = os.listdir(self.base_images_dir)\n",
    "    if not sample_images:\n",
    "        print(\"No images found in base directory\")\n",
    "        return []\n",
    "\n",
    "    random.seed(42)\n",
    "    random.shuffle(sample_images)\n",
    "    selected_samples = sample_images[: min(num_samples, len(sample_images))]\n",
    "\n",
    "    image_paths = [os.path.join(self.base_images_dir, img) for img in selected_samples]\n",
    "\n",
    "    print(f\"Selected images: {selected_samples}\")\n",
    "\n",
    "    try:\n",
    "        results = model.predict(\n",
    "            image_paths,\n",
    "            conf=conf_threshold,\n",
    "            save=True,\n",
    "            show_conf=True,\n",
    "            show_labels=True,\n",
    "            visualize=True,\n",
    "        )\n",
    "\n",
    "        prediction_results = []\n",
    "        for i, (image_file, result) in enumerate(zip(selected_samples, results)):\n",
    "            num_detections = len(result.boxes) if result.boxes is not None else 0\n",
    "\n",
    "            prediction_info = {\n",
    "                \"image_file\": image_file,\n",
    "                \"image_path\": image_paths[i],\n",
    "                \"results\": result,\n",
    "                \"num_detections\": num_detections,\n",
    "            }\n",
    "\n",
    "            prediction_results.append(prediction_info)\n",
    "        return prediction_results\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: batch prediction: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def main():\n",
    "    trainer = LesionYOLOTrainer()\n",
    "\n",
    "    config_path = trainer.prepare_dataset()\n",
    "\n",
    "    # Models:\n",
    "    # yolov8n -> nano version\n",
    "    # yolov8s -> small version\n",
    "    # yolov8m -> medium version\n",
    "    # yolov8l -> large version\n",
    "    # yolov8x -> extra large version\n",
    "    model, results = trainer.train_model(\n",
    "        config_path=config_path,\n",
    "        model_size=\"yolov8l\",\n",
    "        epochs=200,\n",
    "        imgsz=512,\n",
    "    )\n",
    "\n",
    "    metrics = trainer.evaluate_model(model)\n",
    "    sample_images = os.listdir(trainer.base_images_dir)\n",
    "\n",
    "    if sample_images:\n",
    "        sample_path = os.path.join(trainer.base_images_dir, sample_images[0])\n",
    "        predictions = trainer.predict_sample(model, sample_path)\n",
    "\n",
    "    print(f\"Model saved\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vessel_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
